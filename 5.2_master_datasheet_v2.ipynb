{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fbac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: c:\\Users\\quantbase\\.conda\\envs\\sydata-311\\python.exe\n",
      "cwd: C:\\Users\\quantbase\\Desktop\\sydata\n",
      "sys.path[0]: C:\\Users\\quantbase\\Desktop\\sydata\\src\n",
      "SRC exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\quantbase\\Desktop\\sydata\")\n",
    "SRC = PROJECT_ROOT / \"src\"\n",
    "DATA_ROOT = Path(r\"C:\\Users\\quantbase\\Desktop\\marketdata\")\n",
    "MANIFEST = DATA_ROOT / \"meta\" / \"symbols.yml\"\n",
    "\n",
    "# Make `from sydata...` importable\n",
    "sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Make relative paths (scripts/, etc.) resolve predictably\n",
    "os.chdir(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"cwd:\", Path.cwd())\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "print(\"SRC exists:\", SRC.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b943af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SYMBOL = \"BTC-USDT\"\n",
    "INTERVAL = \"1h\"\n",
    "STEP_MS = 3600_000  # 1h in ms\n",
    "\n",
    "START = \"2025-01-01\"\n",
    "END   = \"2026-01-01\"   # exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caf1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Utilities: strict audit + gap locator\n",
    "def audit_kline_frame(df: pd.DataFrame, key: str = \"open_time\", step_ms: int = STEP_MS) -> dict:\n",
    "    out = {}\n",
    "    out[\"rows\"] = int(len(df))\n",
    "    out[\"key_is_unique\"] = bool(df[key].is_unique)\n",
    "    df2 = df.sort_values(key)\n",
    "    v = df2[key].to_numpy()\n",
    "    if len(v) <= 1:\n",
    "        out[\"monotonic\"] = True\n",
    "        out[\"step_ok\"] = True\n",
    "        out[\"min\"] = int(v[0]) if len(v) else None\n",
    "        out[\"max\"] = int(v[0]) if len(v) else None\n",
    "        return out\n",
    "\n",
    "    d = np.diff(v)\n",
    "    out[\"monotonic\"] = bool(np.all(d > 0))\n",
    "    out[\"step_ok\"] = bool(np.all(d == step_ms))\n",
    "    out[\"min\"] = int(v.min())\n",
    "    out[\"max\"] = int(v.max())\n",
    "    out[\"bad_steps\"] = int(np.sum(d != step_ms))\n",
    "    return out\n",
    "\n",
    "\n",
    "def locate_gaps(df: pd.DataFrame, key: str = \"open_time\", step_ms: int = STEP_MS, n: int = 20) -> tuple[int, pd.DataFrame]:\n",
    "    df2 = df.sort_values(key)\n",
    "    v = df2[key].to_numpy()\n",
    "    if len(v) <= 1:\n",
    "        return 0, pd.DataFrame(columns=[\"idx\",\"open_time_prev\",\"open_time_next\",\"delta_ms\",\"ts_prev\",\"ts_next\"])\n",
    "\n",
    "    diff = np.diff(v)\n",
    "    bad = np.where(diff != step_ms)[0]\n",
    "    take = bad[:n]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"idx\": take,\n",
    "        \"open_time_prev\": v[take],\n",
    "        \"open_time_next\": v[take + 1],\n",
    "        \"delta_ms\": diff[take],\n",
    "    })\n",
    "    out[\"ts_prev\"] = pd.to_datetime(out[\"open_time_prev\"], unit=\"ms\", utc=True)\n",
    "    out[\"ts_next\"] = pd.to_datetime(out[\"open_time_next\"], unit=\"ms\", utc=True)\n",
    "    return int(len(bad)), out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa19b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rows': 8760,\n",
       "  'key_is_unique': True,\n",
       "  'monotonic': True,\n",
       "  'step_ok': True,\n",
       "  'min': 1735689600000,\n",
       "  'max': 1767222000000,\n",
       "  'bad_steps': 0},\n",
       "            open_time      open      high       low     close     volume  \\\n",
       " 43816  1735689600000  93576.00  94509.42  93489.03  94401.14  755.99010   \n",
       " 43817  1735693200000  94401.13  94408.72  93578.77  93607.74  586.53456   \n",
       " 43818  1735696800000  93607.74  94105.12  93594.56  94098.91  276.78045   \n",
       " \n",
       "           close_time  quote_volume  trades  taker_buy_base_volume  \\\n",
       " 43816  1735693199999  7.106881e+07   93525              421.08319   \n",
       " 43817  1735696799999  5.509661e+07   79943              257.42023   \n",
       " 43818  1735700399999  2.597409e+07   55078              185.35204   \n",
       " \n",
       "        taker_buy_quote_volume ignore    symbol interval    venue  \\\n",
       " 43816            3.959678e+07      0  BTC-USDT       1h  binance   \n",
       " 43817            2.418794e+07      0  BTC-USDT       1h  binance   \n",
       " 43818            1.739377e+07      0  BTC-USDT       1h  binance   \n",
       " \n",
       "                              ts  \n",
       " 43816 2025-01-01 00:00:00+00:00  \n",
       " 43817 2025-01-01 01:00:00+00:00  \n",
       " 43818 2025-01-01 02:00:00+00:00  )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 — Load spot klines (spine) and time-filter to [START, END)\n",
    "P_SPOT = (\n",
    "    DATA_ROOT\n",
    "    / \"raw\" / \"binance\" / \"klines\"\n",
    "    / f\"symbol={SYMBOL}\" / f\"interval={INTERVAL}\"\n",
    "    / \"part-1577836800000-1767225600000.parquet\"\n",
    ")\n",
    "\n",
    "spot_df = pd.read_parquet(P_SPOT)\n",
    "# strict schema sanity#\n",
    "assert \"open_time\" in spot_df.columns\n",
    "assert \"close\" in spot_df.columns\n",
    "\n",
    "spot_df = spot_df.sort_values(\"open_time\").copy()\n",
    "spot_df[\"ts\"] = pd.to_datetime(spot_df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "spot_df = spot_df[(spot_df[\"ts\"] >= START) & (spot_df[\"ts\"] < END)].copy()\n",
    "\n",
    "spot_audit = audit_kline_frame(spot_df, key=\"open_time\", step_ms=STEP_MS)\n",
    "spot_audit, spot_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b472531e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rows': 8760,\n",
       "  'key_is_unique': True,\n",
       "  'monotonic': True,\n",
       "  'step_ok': True,\n",
       "  'min': 1735689600000,\n",
       "  'max': 1767222000000,\n",
       "  'bad_steps': 0},\n",
       " {'rows': 8760,\n",
       "  'key_is_unique': True,\n",
       "  'monotonic': True,\n",
       "  'step_ok': True,\n",
       "  'min': 1735689600000,\n",
       "  'max': 1767222000000,\n",
       "  'bad_steps': 0},\n",
       "        open_time          open          high           low    close ignore_0  \\\n",
       " 0  1735689600000  93549.661752  94451.045610  93464.441981  94363.6        0   \n",
       " 1  1735693200000  94363.600000  94365.592837  93557.185993  93588.0        0   \n",
       " 2  1735696800000  93588.000000  94087.485142  93574.329979  94064.4        0   \n",
       " \n",
       "       close_time ignore_1 ignore_2 ignore_3 ignore_4 ignore_5    symbol  \\\n",
       " 0  1735693199999        0     3600        0        0        0  BTC-USDT   \n",
       " 1  1735696799999        0     3600        0        0        0  BTC-USDT   \n",
       " 2  1735700399999        0     3600        0        0        0  BTC-USDT   \n",
       " \n",
       "   venue_symbol interval    venue               dataset  \\\n",
       " 0      BTCUSDT       1h  binance  um_mark_price_klines   \n",
       " 1      BTCUSDT       1h  binance  um_mark_price_klines   \n",
       " 2      BTCUSDT       1h  binance  um_mark_price_klines   \n",
       " \n",
       "                          ts  \n",
       " 0 2025-01-01 00:00:00+00:00  \n",
       " 1 2025-01-01 01:00:00+00:00  \n",
       " 2 2025-01-01 02:00:00+00:00  ,\n",
       "        open_time          open          high           low         close  \\\n",
       " 0  1735689600000  93576.022340  94482.167872  93492.683830  94396.002979   \n",
       " 1  1735693200000  94396.002979  94400.512766  93596.391277  93612.465957   \n",
       " 2  1735696800000  93612.465957  94103.941702  93596.894894  94091.546596   \n",
       " \n",
       "   ignore_0     close_time ignore_1 ignore_2 ignore_3 ignore_4 ignore_5  \\\n",
       " 0        0  1735693199999        0     3600        0        0        0   \n",
       " 1        0  1735696799999        0     3600        0        0        0   \n",
       " 2        0  1735700399999        0     3600        0        0        0   \n",
       " \n",
       "      symbol venue_symbol interval    venue                dataset  \\\n",
       " 0  BTC-USDT      BTCUSDT       1h  binance  um_index_price_klines   \n",
       " 1  BTC-USDT      BTCUSDT       1h  binance  um_index_price_klines   \n",
       " 2  BTC-USDT      BTCUSDT       1h  binance  um_index_price_klines   \n",
       " \n",
       "                          ts  \n",
       " 0 2025-01-01 00:00:00+00:00  \n",
       " 1 2025-01-01 01:00:00+00:00  \n",
       " 2 2025-01-01 02:00:00+00:00  )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 — Load UM mark/index klines for the same year and audit\n",
    "MROOT = DATA_ROOT / \"raw\" / \"binance\" / \"um_mark_price_klines\" / f\"symbol={SYMBOL}\" / f\"interval={INTERVAL}\"\n",
    "IROOT = DATA_ROOT / \"raw\" / \"binance\" / \"um_index_price_klines\" / f\"symbol={SYMBOL}\" / f\"interval={INTERVAL}\"\n",
    "\n",
    "mark_files = sorted(MROOT.glob(\"part-2025-*.parquet\"))\n",
    "index_files = sorted(IROOT.glob(\"part-2025-*.parquet\"))\n",
    "assert len(mark_files) > 0 and len(index_files) > 0\n",
    "\n",
    "mark_df = pd.concat([pd.read_parquet(f) for f in mark_files], ignore_index=True).sort_values(\"open_time\")\n",
    "index_df = pd.concat([pd.read_parquet(f) for f in index_files], ignore_index=True).sort_values(\"open_time\")\n",
    "\n",
    "# (optional) time filter to exactly match spot window\n",
    "mark_df[\"ts\"] = pd.to_datetime(mark_df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "index_df[\"ts\"] = pd.to_datetime(index_df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "mark_df = mark_df[(mark_df[\"ts\"] >= START) & (mark_df[\"ts\"] < END)].copy()\n",
    "index_df = index_df[(index_df[\"ts\"] >= START) & (index_df[\"ts\"] < END)].copy()\n",
    "\n",
    "mark_audit = audit_kline_frame(mark_df, key=\"open_time\", step_ms=STEP_MS)\n",
    "index_audit = audit_kline_frame(index_df, key=\"open_time\", step_ms=STEP_MS)\n",
    "\n",
    "(mark_audit, index_audit, mark_df.head(3), index_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d80125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8760, 7),\n",
       "        open_time  spot_close    mark_close   index_close  \\\n",
       " 0  1735689600000    94401.14  94363.600000  94396.002979   \n",
       " 1  1735693200000    93607.74  93588.000000  93612.465957   \n",
       " 2  1735696800000    94098.91  94064.400000  94091.546596   \n",
       " 3  1735700400000    93838.04  93811.972187  93838.176829   \n",
       " 4  1735704000000    93553.91  93544.900000  93555.690851   \n",
       " 5  1735707600000    93792.02  93759.900000  93794.045532   \n",
       " 6  1735711200000    93757.58  93734.200000  93756.584255   \n",
       " 7  1735714800000    93684.10  93661.087326  93687.337447   \n",
       " 8  1735718400000    93428.46  93400.100000  93435.559574   \n",
       " 9  1735722000000    93413.06  93380.168965  93411.669149   \n",
       " \n",
       "                          ts  basis_mark_vs_spot  basis_index_vs_spot  \n",
       " 0 2025-01-01 00:00:00+00:00           -0.000398            -0.000054  \n",
       " 1 2025-01-01 01:00:00+00:00           -0.000211             0.000050  \n",
       " 2 2025-01-01 02:00:00+00:00           -0.000367            -0.000078  \n",
       " 3 2025-01-01 03:00:00+00:00           -0.000278             0.000001  \n",
       " 4 2025-01-01 04:00:00+00:00           -0.000096             0.000019  \n",
       " 5 2025-01-01 05:00:00+00:00           -0.000342             0.000022  \n",
       " 6 2025-01-01 06:00:00+00:00           -0.000249            -0.000011  \n",
       " 7 2025-01-01 07:00:00+00:00           -0.000246             0.000035  \n",
       " 8 2025-01-01 08:00:00+00:00           -0.000304             0.000076  \n",
       " 9 2025-01-01 09:00:00+00:00           -0.000352            -0.000015  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 — Enforce 1:1 key integrity + build master (spot spine, left-join)\n",
    "# Hard fails if duplicates exist on the join key.\n",
    "assert spot_df[\"open_time\"].is_unique\n",
    "assert mark_df[\"open_time\"].is_unique\n",
    "assert index_df[\"open_time\"].is_unique\n",
    "\n",
    "spot_1 = spot_df[[\"open_time\",\"close\"]].rename(columns={\"close\":\"spot_close\"})\n",
    "mark_1 = mark_df[[\"open_time\",\"close\"]].rename(columns={\"close\":\"mark_close\"})\n",
    "index_1 = index_df[[\"open_time\",\"close\"]].rename(columns={\"close\":\"index_close\"})\n",
    "\n",
    "tmp = spot_1.merge(mark_1, on=\"open_time\", how=\"left\", validate=\"one_to_one\")\n",
    "master_df = tmp.merge(index_1, on=\"open_time\", how=\"left\", validate=\"one_to_one\")\n",
    "\n",
    "master_df[\"ts\"] = pd.to_datetime(master_df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "master_df[\"basis_mark_vs_spot\"]  = master_df[\"mark_close\"] / master_df[\"spot_close\"] - 1.0\n",
    "master_df[\"basis_index_vs_spot\"] = master_df[\"index_close\"] / master_df[\"spot_close\"] - 1.0\n",
    "\n",
    "(master_df.shape, master_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64256409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mark_missing_frac': 0.0, 'index_missing_frac': 0.0, 'both_present_frac': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 — Coverage diagnostics (should be near 0 for 2025 if complete)\n",
    "coverage = {\n",
    "    \"mark_missing_frac\": float(master_df[\"mark_close\"].isna().mean()),\n",
    "    \"index_missing_frac\": float(master_df[\"index_close\"].isna().mean()),\n",
    "    \"both_present_frac\": float((master_df[\"mark_close\"].notna() & master_df[\"index_close\"].notna()).mean()),\n",
    "}\n",
    "coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcfbd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spot_keys': 8760,\n",
       " 'mark_keys': 8760,\n",
       " 'index_keys': 8760,\n",
       " 'spot_minus_mark': 0,\n",
       " 'spot_minus_index': 0,\n",
       " 'mark_minus_spot': 0,\n",
       " 'index_minus_spot': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 — Key-set equality checks (spot vs mark/index)\n",
    "s_spot = set(master_df[\"open_time\"])\n",
    "s_mark = set(mark_1[\"open_time\"])\n",
    "s_idx  = set(index_1[\"open_time\"])\n",
    "\n",
    "keyset_report = {\n",
    "    \"spot_keys\": len(s_spot),\n",
    "    \"mark_keys\": len(s_mark),\n",
    "    \"index_keys\": len(s_idx),\n",
    "    \"spot_minus_mark\": len(s_spot - s_mark),\n",
    "    \"spot_minus_index\": len(s_spot - s_idx),\n",
    "    \"mark_minus_spot\": len(s_mark - s_spot),\n",
    "    \"index_minus_spot\": len(s_idx - s_spot),\n",
    "}\n",
    "keyset_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd4088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [open_time, ts]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [open_time, ts]\n",
       " Index: [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 — If keyset differences exist, view examples\n",
    "def show_missing_examples(base: set, other: set, n: int = 10):\n",
    "    xs = sorted(list(base - other))[:n]\n",
    "    return pd.DataFrame({\n",
    "        \"open_time\": xs,\n",
    "        \"ts\": pd.to_datetime(xs, unit=\"ms\", utc=True),\n",
    "    })\n",
    "\n",
    "missing_mark_ex = show_missing_examples(s_spot, s_mark, n=25)\n",
    "missing_idx_ex  = show_missing_examples(s_spot, s_idx, n=25)\n",
    "\n",
    "missing_mark_ex, missing_idx_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aaec01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                          ts  spot_close    mark_close   index_close  \\\n",
       " 0  2025-01-01 00:00:00+00:00    94401.14  94363.600000  94396.002979   \n",
       " 1  2025-01-01 01:00:00+00:00    93607.74  93588.000000  93612.465957   \n",
       " 2  2025-01-01 02:00:00+00:00    94098.91  94064.400000  94091.546596   \n",
       " 3  2025-01-01 03:00:00+00:00    93838.04  93811.972187  93838.176829   \n",
       " 4  2025-01-01 04:00:00+00:00    93553.91  93544.900000  93555.690851   \n",
       " 5  2025-01-01 05:00:00+00:00    93792.02  93759.900000  93794.045532   \n",
       " 6  2025-01-01 06:00:00+00:00    93757.58  93734.200000  93756.584255   \n",
       " 7  2025-01-01 07:00:00+00:00    93684.10  93661.087326  93687.337447   \n",
       " 8  2025-01-01 08:00:00+00:00    93428.46  93400.100000  93435.559574   \n",
       " 9  2025-01-01 09:00:00+00:00    93413.06  93380.168965  93411.669149   \n",
       " 10 2025-01-01 10:00:00+00:00    93326.23  93303.200000  93325.870000   \n",
       " 11 2025-01-01 11:00:00+00:00    93444.64  93427.950241  93452.544468   \n",
       " 12 2025-01-01 12:00:00+00:00    93820.76  93790.861220  93819.680851   \n",
       " 13 2025-01-01 13:00:00+00:00    94031.76  94000.851000  94030.125319   \n",
       " 14 2025-01-01 14:00:00+00:00    94175.89  94147.200000  94174.537234   \n",
       " 15 2025-01-01 15:00:00+00:00    94432.94  94413.600000  94433.477660   \n",
       " 16 2025-01-01 16:00:00+00:00    94090.49  94079.750106  94089.554894   \n",
       " 17 2025-01-01 17:00:00+00:00    94143.85  94127.346518  94136.025319   \n",
       " 18 2025-01-01 18:00:00+00:00    94340.06  94323.559489  94338.864255   \n",
       " 19 2025-01-01 19:00:00+00:00    94627.07  94621.418773  94629.805745   \n",
       " \n",
       "     funding_rate  \n",
       " 0         0.0001  \n",
       " 1         0.0001  \n",
       " 2         0.0001  \n",
       " 3         0.0001  \n",
       " 4         0.0001  \n",
       " 5         0.0001  \n",
       " 6         0.0001  \n",
       " 7         0.0001  \n",
       " 8         0.0001  \n",
       " 9         0.0001  \n",
       " 10        0.0001  \n",
       " 11        0.0001  \n",
       " 12        0.0001  \n",
       " 13        0.0001  \n",
       " 14        0.0001  \n",
       " 15        0.0001  \n",
       " 16        0.0001  \n",
       " 17        0.0001  \n",
       " 18        0.0001  \n",
       " 19        0.0001  ,\n",
       " 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10 — Optional: attach funding (as-of backward, no lookahead)\n",
    "FROOT = DATA_ROOT / \"raw\" / \"binance\" / \"um_funding_rate\" / f\"symbol={SYMBOL}\"\n",
    "fund_files = sorted(FROOT.glob(\"part-2025-*.parquet\"))\n",
    "assert len(fund_files) > 0\n",
    "\n",
    "fund_df = pd.concat([pd.read_parquet(f) for f in fund_files], ignore_index=True).sort_values(\"ts\")\n",
    "fund_df = fund_df[(fund_df[\"ts\"] >= START) & (fund_df[\"ts\"] < END)].copy()\n",
    "\n",
    "master_df = pd.merge_asof(\n",
    "    master_df.sort_values(\"ts\"),\n",
    "    fund_df[[\"ts\",\"funding_rate\",\"funding_interval_hours\"]].sort_values(\"ts\"),\n",
    "    on=\"ts\",\n",
    "    direction=\"backward\",\n",
    ")\n",
    "\n",
    "(master_df[[\"ts\",\"spot_close\",\"mark_close\",\"index_close\",\"funding_rate\"]].head(20),\n",
    " float(master_df[\"funding_rate\"].isna().mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71380e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Saving-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73445a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sydata-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
